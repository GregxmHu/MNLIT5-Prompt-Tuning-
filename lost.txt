commit d4cd6233821353e966ac7c74955f76520142b2e5
Merge: e425bde cce6d06
Author: GregxmHu <hxm183083@gmail.com>
Date:   Thu Dec 2 10:32:31 2021 +0800

    WIP on master: e425bde new t5

diff --cc mnli_dataset.py
index d4d7cfe,d4d7cfe..9863f33
--- a/mnli_dataset.py
+++ b/mnli_dataset.py
@@@ -15,20 -15,20 +15,13 @@@ class MNLIDataset(Dataset)
          tokenizer: T5Tokenizer,
          max_input: int = 1280000,
      ) -> None:
--        self._label_mapping = ['entailment', 'neutral', 'contradiction']
--        #对应[1176,7163,6136]
++        self._label_mapping=['entailment', 'neutral', 'contradiction']
          self._dataset = dataset
          self._tokenizer = tokenizer
          self._max_input = max_input
          with open(self._dataset,'r') as f:
              self._examples=[eval(line) for line in f]        
  

  
      def __getitem__(self, index: int) -> Dict[str, Any]:
          example = self._examples[index]
@@@ -46,27 -46,27 +39,17 @@@
              "attention_mask": source_mask,
              "labels": target_ids,
              "raw_label": raw_label

          }
          return output
  
      def __len__(self) -> int:
          return len(self._examples)
  

  
      def collate(self, batch: Dict[str, Any]):
          input_ids = torch.tensor([item['input_ids'] for item in batch])

          attention_mask = torch.tensor([item['attention_mask'] for item in batch])
          labels = torch.tensor([item['labels'] for item in batch])
          raw_label = [item["raw_label"] for item in batch]
++        return {'input_ids': input_ids, "attention_mask": attention_mask, 'labels': labels, "raw_label": raw_label}
++
diff --cc mnli_model.py
index 1221ef1,1221ef1..7e1c2c5
--- a/mnli_model.py
+++ b/mnli_model.py
@@@ -4,7 -4,7 +4,6 @@@ import torc
  class MNLIT5(nn.Module):
      def __init__(self,checkpoint:str):
          super(MNLIT5,self).__init__()
          self.t5=T5ForConditionalGeneration.from_pretrained(checkpoint)      
      
      def forward(self,input_ids,attention_mask,decoder_input_ids):
diff --cc run.sh
index b106e7a,b106e7a..2ea0d38
+++ b/run.sh
@@@ -1,17 -1,17 +1,17 @@@
  set -ex
++export CUDA_VISIBLE_DEVICES=0,3
++LR=2e-5
  
++MAX_STEPS=1000
  EPOCH=6
  
--LOG_STEP=100
--EVAL_EVERY=500
++LOG_STEP=10
++EVAL_EVERY=100
  
  BATCH_SIZE=8
  
  
--pretrained_ckpt="/home/huxiaomeng/t5v11large/"
++pretrained_ckpt="t5-large"
  # pretrained_ckpt="/data/private/yushi/pretrained_models/t5-large"
  
  python -m torch.distributed.launch \
@@@ -22,6 -22,6 +22,7 @@@
          -max_input 80000000  \
          -save /data/private/huxiaomeng/promptir/checkpoints/mnli/  \
          -dev /data/private/huxiaomeng/promptir/dataset/mnli/val_mismatch.jsonl   \
++        -test /data/private/
          -vocab $pretrained_ckpt          \
          -pretrain $pretrained_ckpt   \
          -res results.jsonl  \
diff --cc train.py
index be679a0,be679a0..3277371
--- a/train.py
+++ b/train.py
@@@ -32,7 -32,7 +32,22 @@@ import jso
  import os
  os.environ["TOKENIZERS_PARALLELISM"] = "false"
  

++def test(args, model, test_loader, device, tokenizer):
++    total=0
++    right=0
++    for test_batch in tqdm(test_loader, disable=args.local_rank not in [-1, 0]):
++        #query_id, doc_id, label= test_batch[''], test_batch['doc_id'], test_batch['label']
++        with torch.no_grad():
++            batch_score = model(
++                    input_ids=test_batch['input_ids'].to(device), 
++                    attention_mask=test_batch['attention_mask'].to(device), 
++                    decoder_input_ids=test_batch['decoder_input_ids'].to(device),
++                    )
++            predict=torch.argmax(batch_score,dim=1)
++            label=test_batch['label'].to(device)
++            total+=len(label)
++            right+=torch.eq(predict,label).sum()
++    return total, right
  
  
  def dev(args, model, dev_loader, device, tokenizer):
@@@ -41,30 -41,30 +56,15 @@@
      for dev_batch in tqdm(dev_loader, disable=args.local_rank not in [-1, 0]):
          #query_id, doc_id, label= dev_batch[''], dev_batch['doc_id'], dev_batch['label']
          with torch.no_grad():
++            batch_score = model(
++                    input_ids=dev_batch['input_ids'].to(device), 
++                    attention_mask=dev_batch['attention_mask'].to(device), 
++                    decoder_input_ids=dev_batch['decoder_input_ids'].to(device),
++                    )
++            predict=torch.argmax(batch_score,dim=1)
++            label=dev_batch['label'].to(device)
++            total+=len(label)
++            right+=torch.eq(predict,label).sum()
      return total, right
  
  
@@@ -75,7 -75,7 +75,7 @@@ def batch_to_device(batch, device)
      return device_batch
              
  
++def train(args, model, loss_fn, m_optim, m_scheduler, train_loader, dev_loader, test_loader,device, train_sampler=None, tokenizer=None):
      best_mes = 0.0
      global_step = 0 # steps that outside epoches
      force_break = False
@@@ -88,22 -88,22 +88,14 @@@
          for step, train_batch in enumerate(train_loader):
              # print("Before: global step {}, rank {}".format(global_step, args.local_rank))
              sync_context = model.no_sync if (args.local_rank != -1 and (step+1) % args.gradient_accumulation_steps != 0) else nullcontext

++            with sync_context():
++                batch_score = model(
++                    input_ids=train_batch['input_ids'].to(device), 
++                    attention_mask=train_batch['attention_mask'].to(device), 
++                    decoder_input_ids=train_batch['decoder_input_ids'].to(device),
++                    )
++            with sync_context():
++                batch_loss = loss_fn(batch_score, train_batch['label'].to(device))
  
              if args.n_gpu > 1:
                  batch_loss = batch_loss.mean()
@@@ -138,10 -138,10 +130,10 @@@
                          total,right=dev(args, model, dev_loader, device, tokenizer)
                      model.train()
  
++                    with open(args.res,'a+') as f:
++                        f.write(json.dumps({'total':total,'right':right}))
++                        f.write('\n')
                      if args.local_rank != -1:
                          dist.barrier()
                      if args.local_rank in [-1,0]:
                          with open(args.res,'r') as f:
@@@ -151,8 -151,8 +143,21 @@@
                                  t+=eval(line)['total']
                                  print(r,t)
                              mes=r/t
++                        os.remove(args.res)#logger.info('save_model at step {}'.format(global_step+1))
++                        if not os.path.exists(args.save):
++                                os.makedirs(args.save)
++                        if mes>best_mes:
++                            best_mes=mes
++                            ls=os.listdir(args.save)
++                            for i in ls:
++                                item_path=os.path.join(args.save,i)
++                                logger.info('remove_model at step {}'.format(global_step+1))
++                                logger.info('save model')
++                                os.remove(item_path)
++                            if hasattr(model, "module"):
++                                torch.save(model.module.state_dict(), args.save + "_step-{}.bin".format(global_step+1))
++                            else:
++                                torch.save(model.state_dict(), args.save + "_step-{}.bin".format(global_step+1))
                          logger.info("global step: {}, messure: {}, best messure: {}".format(global_step+1, mes, best_mes))
                  
                  global_step += 1
@@@ -160,32 -160,32 +165,79 @@@
                  if args.max_steps is not None and global_step == args.max_steps:
                      force_break = True
                      break
++
              if args.local_rank != -1:
                  dist.barrier()
++
          if args.local_rank != -1:
              dist.barrier()
          if force_break:
              break
      if args.local_rank != -1:
          dist.barrier()
++        logger.info("load best checkpoint....")
++        dist.barrier()
++        for file in os.listdir(args.save):
++            checkpoint=os.path.join(args.save,file)
++            state=torch.load(checkpoint,map_location=device)
++            model.module.load_state_dict(state)
++        dist.barrier()
++    else:
++        logger.info("load best checkpoint....")
++        for file in os.listdir(args.save):
++            checkpoint=os.path.join(args.save,file)
++            state=torch.load(checkpoint,map_location=device)
++            model.load_state_dict(state)
++    logger.info("doing inference.... at gpu:{}".format(args.local_rank))
++    model.eval()
++    if args.local_rank != -1:
++        dist.barrier()
++    with torch.no_grad():
++        total,right = test(args, model,test_loader, device,tokenizer=tokenizer)
++    if args.local_rank != -1:
++        logger.info("inference finished...at gpu:{}".format(args.local_rank))
++        dist.barrier()
++    else:
++        logger.info("inference finished...")
++    with open(args.res,'a+') as f:
++        f.write(json.dumps({'total':total,'right':right}))
++        f.write('\n')
++    if args.local_rank != -1:
++        dist.barrier()
++    if args.local_rank in [-1,0]:
++        with open(args.res,'r') as f:
++            r,t=0,0
++            for line in f:
++                r+=eval(line)['right']
++                t+=eval(line)['total']
++                print(r,t)
++            mes=r/t
++            print("test_acc:{}".format(mes))
++    if args.local_rank !=-1:
++        dist.barrier()
++    dist.barrier()
  
++    return 
  
++def set_seed(seed):
++    random.seed(seed)
++    np.random.seed(seed)
++    torch.manual_seed(seed)
++    if torch.cuda.is_available():
++        torch.cuda.manual_seed_all(seed)
  def main():
      parser = argparse.ArgumentParser()
      parser.add_argument('-optimizer', type=str, default='adam')
      parser.add_argument('-train', type=str, default='./data/train_toy.jsonl')
++    parser.add_argument('-dev', type=str, default='./data/dev_toy.jsonl')
++    parser.add_argument('-test', type=str, default='./data/dev_toy.jsonl')
      parser.add_argument('-max_input', type=int, default=1280000)
      parser.add_argument('-save', type=str, default='./checkpoints/bert.bin')
      parser.add_argument('-vocab', type=str, default='allenai/scibert_scivocab_uncased')
      parser.add_argument('-pretrain', type=str, default='allenai/scibert_scivocab_uncased')
      parser.add_argument('-checkpoint', type=str, default=None)
      parser.add_argument('-res', type=str, default='./results/bert.trec')
++    parser.add_argument('-test_res', type=str, default='./results/bert.trec')
      parser.add_argument('-epoch', type=int, default=1)
      parser.add_argument('-batch_size', type=int, default=8)
      parser.add_argument('-dev_eval_batch_size', type=int, default=128)
@@@ -205,8 -205,8 +257,8 @@@
      parser.add_argument('-tau', type=float, default=1)
      parser.add_argument('-n_kernels', type=int, default=21)
      parser.add_argument('-right',type=int,default=0)
      args = parser.parse_args()
++    set_seed(13)
      set_dist_args(args) # get local cpu/gpu device
      if args.log_dir is not None:
          writer = SummaryWriter(args.log_dir)
@@@ -218,8 -218,8 +270,9 @@@
      logger.info('reading training data...')
      train_set=MNLIDataset(dataset=args.train,tokenizer=tokenizer)
      logger.info('reading dev data...')
++    dev_set=MNLIDataset(dataset=args.dev,tokenizer=tokenizer, max_input=2000)
++    logger.info('reading test data...')
++    test_set=MNLIDataset(dataset=args.tset,tokenizer=tokenizer, max_input=100000)
      if args.local_rank != -1:
          
          train_sampler = DistributedSampler(train_set)
@@@ -238,9 -238,9 +291,17 @@@
              num_workers=8,
              sampler=dev_sampler
          )
++        test_sampler = DistributedEvalSampler(test_set)
++        test_loader = MNLIDataLoader(
++            dataset=test_set,
++            batch_size=args.batch_size * 16 if args.dev_eval_batch_size <= 0 else args.dev_eval_batch_size,
++            shuffle=False,
++            num_workers=8,
++            sampler=test_sampler
++        )
          dist.barrier()
  
++    model = MNLIT5(args.pretrain)
  
      device = args.device
      loss_fn = nn.CrossEntropyLoss()
@@@ -292,8 -292,8 +353,9 @@@
          optimizer_to(m_optim,device)
  
      logger.info(args)
++    train(args, model, loss_fn, m_optim, m_scheduler,  train_loader, dev_loader,test_loader, device, train_sampler=train_sampler, tokenizer=tokenizer)
      if args.local_rank != -1:
          dist.barrier()
  if __name__ == "__main__":
      main()
++    os._exit()
diff --cc utils.py
index ae8d494,ae8d494..350517e
--- a/utils.py
+++ b/utils.py
@@@ -7,6 -7,6 +7,10 @@@ from torch.utils.data import DataLoader
  import math
  import logging
  
++
++import os
++import json
++from argparse import Action
  import random
  import numpy as np
  
@@@ -198,4 -198,4 +202,35 @@@ def optimizer_to(optim, device)
                      if subparam._grad is not None:
                          subparam._grad.data = subparam._grad.data.to(device)
  
++# create new OrderedDict that does not contain `module.`
++
++
++class DictOrStr(Action):
++    def __call__(self, parser, namespace, values, option_string=None):
++         if '=' in values:
++             my_dict = {}
++             for kv in values.split(","):
++                 k,v = kv.split("=")
++                 my_dict[k] = v
++             setattr(namespace, self.dest, my_dict)
++         else:
++             setattr(namespace, self.dest, values)
++
++def check_dir(path):
++    if not os.path.exists(path):
++        os.makedirs(path)
++    return path
++
++def save_trec(rst_file, rst_dict):
++    with open(rst_file, 'a') as writer:
++        for q_id, scores in rst_dict.items():
++            res = sorted(scores.items(), key=lambda x: x[1][0], reverse=True)
++            for rank, value in enumerate(res):
++                writer.write(str(q_id)+' Q0 '+str(value[0])+' '+str(rank+1)+' '+str(value[1][0])+' openmatch\n')
++    return
++
++def save_features(rst_file, features):
++    with open(rst_file, 'w') as writer:
++        for feature in features:
++            writer.write(feature+'\n')
++    return
